{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Naive Bayes.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"kL2lrF_FYyE_"},"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NsSaaVIobxl0","executionInfo":{"status":"error","timestamp":1640937148076,"user_tz":-360,"elapsed":356,"user":{"displayName":"Hasibul Hasan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjg-8qyn-Y6WG3owqvn9wfRwmqADwwBkHnW_Bvz6g=s64","userId":"00451471846498296598"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"46decf62-be44-41d4-c0b0-e20f1c694489"},"source":["df = pd.read_csv(\"WA_Fn_UseC_Telco_Customer_Churn.csv\",na_values=[\"No internet service\",\"No phone service\"])"],"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-02333df1dd76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"WA_Fn_UseC_Telco_Customer_Churn.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mna_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"No internet service\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"No phone service\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'WA_Fn_UseC_Telco_Customer_Churn.csv'"]}]},{"cell_type":"code","metadata":{"id":"zmhBYOo6dsh3"},"source":["df.dropna(inplace=True)\n","\n","df.reset_index(drop=True)\n","\n","df.dropna()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ppaa1t3reOKn"},"source":["df = df.replace({\n","    \"Churn\": {\n","        \"Yes\" : 1,\n","        \"No\" : 0\n","    }\n","})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yI1X8Pmji-Jv"},"source":["#To Drop Unnecessary Columns\n","\n","df.drop(labels=[\"customerID\", \"Partner\", \"StreamingTV\", \"PhoneService\"], \n","        axis=1,\n","        inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MFaq0lRguJxD"},"source":["#Find Categorical and Numerical Columns\n","\n","categorical_columns = pd.DataFrame(df, columns = [\"gender\", \"Dependents\", \"MultipleLines\", \"InternetService\",\n","                       \"OnlineSecurity\", \"OnlineBackup\", \"DeviceProtection\", \"TechSupport\", \n","                       \"StreamingMovies\", \"Contract\", \"PaperlessBilling\", \"PaymentMethod\"])\n","numerical_columns = pd.DataFrame(df, columns = [\"SeniorCitizen\", \"tenure\", \"TotalCharges\", \"MonthlyCharges\"])                       "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OYf9bWYzwo2b"},"source":["categorical_columns.dropna()\n","numerical_columns.dropna()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6TrAoAkzyora"},"source":["#define feature matrix and response vector\n","\n","data_x = categorical_columns.loc[:] #categorical_columns.columns != \"Churn\"\n","data_y = df[\"Churn\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lnuqTSvyy0AH"},"source":["#Dropping the Numerical Columns\n","'''\n","numerical_columns.drop(labels=numerical_columns, \n","        axis=1,\n","        inplace=True)\n","'''        "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bvPgIL600bpt"},"source":["print(categorical_columns)  #Return Empty DataFrame"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OaT6xBTu0qyQ"},"source":["#Split the dataset (80% training, 20% testing) both with and without stratification (use random_state = 911)\n","\n","X_train, X_test, y_train, y_test = train_test_split(data_x, data_y, train_size = 0.8, random_state=911)  #Without stratify\n","\n","X_train_stratified, X_test_stratified, y_train_stratified, y_test_stratified = train_test_split(\n","                                                                                                    data_x, data_y, \n","                                                                                                    train_size = 0.8, stratify = data_y,\n","                                                                                                    random_state = 911 )  #With stratify"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oizPoXHNZXfB"},"source":["**Data are now Preprocessed**"]},{"cell_type":"code","metadata":{"id":"yp8yvPiUaIQr"},"source":["def calc_event_frequency(col, lbl):\n","    tmp_list = []\n","    u = None\n","    total_yes = total_no = 0\n","\n","    unique_events, num_of_events = np.unique(col, return_counts=True)\n","    \n","    for i in range(len(unique_events)):\n","        u = unique_events[i]\n","        count_yes = 0\n","        count_no = 0\n","        for j in range(len(col)):\n","            if col[j] == u and lbl[j] == 1: #yes\n","                count_yes += 1      #sum of total yes for a particular unique event\n","                total_yes += 1      #sum of total yes in the label set for all the unique events   \n","            elif col[j] == u and lbl[j] == 0: #No\n","                count_no += 1\n","                total_no += 1\n","        tmp_list.append(list([u, count_yes, count_no])) #[unique_event, P(event|yes), P(event|no)]\n","    \n","    for k in range(len(unique_events)): #calculating the probabilities for all the unique events in a particular feature/column,\n","        tmp_list[k][1] /= total_yes     #P(feature|yes)\n","        tmp_list[k][2] /= total_no      #P(feature|no)\n","    \n","    return tmp_list  \n","\n","def fit(features, response):\n","    features = np.array(features)\n","    response = np.array(response)\n","    list_of_likelihood = []\n","    unique_elements, counts_elements = np.unique(response, return_counts=True) \n","    \n","    # to get frequency of elements (counts_elements[1])\n","    p_of_no = (counts_elements[0] / (counts_elements[0] + counts_elements[1]))\n","    p_of_yes = (counts_elements[1] / (counts_elements[0] + counts_elements[1]))\n","    \n","    for col in range(features.shape[1]):\n","        each_column = features[:, col] #slicing each column\n","        unique_events, num_of_events = np.unique(each_column, return_counts=True)\n","        list_of_likelihood.append(calc_event_frequency(each_column, response))       #List of List for a complete feature\n","    \n","    return list_of_likelihood, p_of_yes, p_of_no    \n","        \n","probability_table = []   # [index(feature name),[probabilities for each unique events]]\n","probability_table, p_of_yes, p_of_no = fit(X_train, y_train)\n","for i in range(len(probability_table)):\n","    print(probability_table[i])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZVr3FR2l6THz"},"source":["def predict(features, prob_table, p_yes, p_no):\n","    features = np.array(features)\n","    tmp = []\n","    for i in range(len(features)):  \n","        pred_yes = 1\n","        pred_no = 1\n","\n","        for j in range(len(features[i])):\n","            for k in range(len(probability_table[j])):\n","                if features[i][j] == probability_table[j][k][0]:\n","                    pred_yes *= probability_table[j][k][1]\n","                    pred_no *= probability_table[j][k][2]\n","        pred_yes *= p_yes\n","        pred_no *= p_no\n","        if pred_yes >= pred_no:\n","            tmp.append(1)\n","        else:\n","            tmp.append(0)\n","    return tmp\n","decesion_list = predict(X_test, probability_table, p_of_yes, p_of_no)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JjqJ5TiGBNGK"},"source":["def confusion_matrix(decesion_list, y_test):\n","    y_test = y_test.to_list()\n","    \n","    tp = tn = fp = fn = 0\n","    for i in range(len(decesion_list)):\n","        if decesion_list[i] == 1 and y_test[i] == 1:\n","            tp += 1\n","        elif decesion_list[i] == 0 and y_test[i] == 0:\n","            tn += 1\n","        elif decesion_list[i] == 0 and y_test[i] == 1:\n","            fn += 1 \n","        elif decesion_list[i] == 1 and y_test[i] == 0:\n","            fp += 1\n","    return tp, tn, fn, fp\n","\n","tp, tn, fn, fp = confusion_matrix(decesion_list, y_test) \n","\n","print(\"TP = {}, TN = {}, FP = {}, FN = {}\".format(tp, tn, fp, fn))\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iXpxQMt-QhRj"},"source":["\n","def precision_score(tp, tn, fn, fp):\n","    return ( tp / (fp + tp) )\n","def accuracy_score(tp, tn, fn, fp):\n","    return  (tp + tn)/ (tp + fn + tn + fp)\n","def recall_score(tp, tn, fn, fp):\n","    return tp / (fn + tp)\n","def f1_score(tp, tn, fn, fp):\n","    return 2* precision_score(tp, tn, fn, fp) * recall_score(tp, tn, fn, fp) / (precision_score(tp, tn, fn, fp) + recall_score(tp, tn, fn, fp))\n","\n","print(\"Precision Score = {}\".format(precision_score(tp, tn, fn, fp)))    \n","print(\"Accuracy Score = {}\".format(accuracy_score(tp, tn, fn, fp)))    \n","print(\"Recall Score = {}\".format(recall_score(tp, tn, fn, fp)))    \n","print(\"F-1 Score = {}\".format(f1_score(tp, tn, fn, fp)))  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C1s98T2mmCQj"},"source":["**For Numerical features colums**"]},{"cell_type":"code","metadata":{"id":"V0MlEhwImB40"},"source":["numerical_data_x = numerical_columns.loc[:] #categorical_columns.columns != \"Churn\"\n","numerical_data_y = df[\"Churn\"]\n","\n","\n","def numerical_fit(features, labels):\n","    \n","\n","\n","print(type(numerical_data_y))"],"execution_count":null,"outputs":[]}]}